{"dependencies":[{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\package.json","includedInParent":true,"mtime":1528200878026},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\.babelrc","includedInParent":true,"mtime":1528197961732},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1524501157000},{"name":"@tensorflow/tfjs-core","loc":{"line":13,"column":26}},{"name":"../backend/tfjs_backend","loc":{"line":14,"column":16}},{"name":"../constraints","loc":{"line":15,"column":28}},{"name":"../engine/topology","loc":{"line":16,"column":25}},{"name":"../errors","loc":{"line":17,"column":23}},{"name":"../initializers","loc":{"line":18,"column":29}},{"name":"../regularizers","loc":{"line":19,"column":29}},{"name":"../utils/generic_utils","loc":{"line":20,"column":28}},{"name":"../utils/math_utils","loc":{"line":21,"column":27}}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar K = require(\"../backend/tfjs_backend\");\nvar constraints_1 = require(\"../constraints\");\nvar topology_1 = require(\"../engine/topology\");\nvar errors_1 = require(\"../errors\");\nvar initializers_1 = require(\"../initializers\");\nvar regularizers_1 = require(\"../regularizers\");\nvar generic_utils = require(\"../utils/generic_utils\");\nvar math_utils_1 = require(\"../utils/math_utils\");\nvar BatchNormalization = (function (_super) {\n    __extends(BatchNormalization, _super);\n    function BatchNormalization(config) {\n        var _this = _super.call(this, config) || this;\n        _this.supportsMasking = true;\n        _this.axis = config.axis == null ? -1 : config.axis;\n        _this.momentum = config.momentum == null ? 0.99 : config.momentum;\n        _this.epsilon = config.epsilon == null ? 1e-3 : config.epsilon;\n        _this.center = config.center == null ? true : config.center;\n        _this.scale = config.scale == null ? true : config.scale;\n        _this.betaInitializer = initializers_1.getInitializer(config.betaInitializer || 'zeros');\n        _this.gammaInitializer = initializers_1.getInitializer(config.gammaInitializer || 'ones');\n        _this.movingMeanInitializer =\n            initializers_1.getInitializer(config.movingMeanInitializer || 'zeros');\n        _this.movingVarianceInitializer =\n            initializers_1.getInitializer(config.movingVarianceInitializer || 'ones');\n        _this.betaConstraint = constraints_1.getConstraint(config.betaConstraint);\n        _this.gammaConstraint = constraints_1.getConstraint(config.gammaConstraint);\n        _this.betaRegularizer = regularizers_1.getRegularizer(config.betaRegularizer);\n        _this.gammaRegularizer = regularizers_1.getRegularizer(config.gammaRegularizer);\n        _this.stepCount = 0;\n        return _this;\n    }\n    BatchNormalization.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var axis = this.axis >= 0 ? this.axis : (this.axis + inputShape.length);\n        var dim = inputShape[axis];\n        if (dim == null) {\n            throw new errors_1.ValueError(\"Axis \" + axis + \" of input tensor should have a defined dimension but \" +\n                \"the layer received an input with shape \" +\n                (JSON.stringify(inputShape) + \".\"));\n        }\n        this.inputSpec =\n            [new topology_1.InputSpec({ ndim: inputShape.length, axes: (_a = {}, _a[axis] = dim, _a) })];\n        var shape = [dim];\n        if (this.scale) {\n            this.gamma = this.addWeight('gamma', shape, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint);\n        }\n        if (this.center) {\n            this.beta = this.addWeight('beta', shape, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint);\n        }\n        this.movingMean = this.addWeight('moving_mean', shape, null, this.movingMeanInitializer, null, false);\n        this.movingVariance = this.addWeight('moving_variance', shape, null, this.movingVarianceInitializer, null, false);\n        this.built = true;\n        var _a;\n    };\n    BatchNormalization.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            var training = kwargs['training'] == null ? false : kwargs['training'];\n            var input = generic_utils.getExactlyOneTensor(inputs);\n            var inputShape = K.shape(input);\n            var ndim = inputShape.length;\n            var reductionAxes = math_utils_1.range(0, ndim);\n            var axis = _this.axis >= 0 ? _this.axis : (_this.axis + ndim);\n            reductionAxes.splice(axis, 1);\n            var broadcastShape = generic_utils.pyListRepeat(1, ndim);\n            broadcastShape[axis] = inputShape[axis];\n            var sortedReductionAxes = reductionAxes.slice();\n            sortedReductionAxes.sort();\n            var needsBroadcasting = !tfjs_core_1.util.arraysEqual(sortedReductionAxes, math_utils_1.range(0, ndim).slice(0, ndim - 1));\n            var normalizeInference = function () {\n                if (needsBroadcasting) {\n                    var broadcastMovingMean = K.reshape(_this.movingMean.read(), broadcastShape);\n                    var broadcastMovingVariance = K.reshape(_this.movingVariance.read(), broadcastShape);\n                    var broadcastBeta = _this.center ? K.reshape(_this.beta.read(), broadcastShape) : null;\n                    var broadcastGamma = _this.scale ? K.reshape(_this.gamma.read(), broadcastShape) : null;\n                    return K.batchNormalization(input, broadcastMovingMean, broadcastMovingVariance, broadcastBeta, broadcastGamma, _this.epsilon);\n                }\n                else {\n                    return K.batchNormalization(input, _this.movingMean.read(), _this.movingVariance.read(), _this.beta == null ? null : _this.beta.read(), _this.gamma == null ? null : _this.gamma.read(), _this.epsilon);\n                }\n            };\n            if (!training) {\n                return normalizeInference();\n            }\n            var _a = K.normalizeBatchInTraining(input, _this.gamma.read(), _this.beta.read(), reductionAxes, _this.epsilon), normedTraining = _a[0], mean = _a[1], variance = _a[2];\n            var sampleSize = math_utils_1.arrayProd(reductionAxes.map(function (axis) { return input.shape[axis]; }));\n            var varianceDebiased = variance.mul(K.getScalar(sampleSize / (sampleSize - (1 + _this.epsilon))));\n            var updateMovingMeanAndVariance = function () {\n                _this.stepCount++;\n                var newMovingMean = tfjs_core_1.movingAverage(_this.movingMean.read(), mean, _this.momentum, _this.stepCount);\n                _this.movingMean.write(newMovingMean);\n                var newMovingVariance = tfjs_core_1.movingAverage(_this.movingVariance.read(), varianceDebiased, _this.momentum, _this.stepCount);\n                _this.movingVariance.write(newMovingVariance);\n            };\n            updateMovingMeanAndVariance();\n            return normedTraining;\n        });\n    };\n    BatchNormalization.prototype.getClassName = function () {\n        return 'BatchNormalization';\n    };\n    BatchNormalization.prototype.getConfig = function () {\n        var config = {\n            axis: this.axis,\n            momentum: this.momentum,\n            epsilon: this.epsilon,\n            center: this.center,\n            scale: this.scale,\n            betaInitializer: initializers_1.serializeInitializer(this.betaInitializer),\n            gammaInitializer: initializers_1.serializeInitializer(this.gammaInitializer),\n            movingMeanInitializer: initializers_1.serializeInitializer(this.movingMeanInitializer),\n            movingVarianceInitializer: initializers_1.serializeInitializer(this.movingVarianceInitializer),\n            betaRegularizer: regularizers_1.serializeRegularizer(this.betaRegularizer),\n            gammaRegularizer: regularizers_1.serializeRegularizer(this.gammaRegularizer),\n            betaConstraint: constraints_1.serializeConstraint(this.betaConstraint),\n            gammaConstraint: constraints_1.serializeConstraint(this.gammaConstraint)\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return BatchNormalization;\n}(topology_1.Layer));\nexports.BatchNormalization = BatchNormalization;\ngeneric_utils.ClassNameMap.register('BatchNormalization', BatchNormalization);\n"},"hash":"dc038375b99bc04de0880cf22b16c5d6","cacheData":{"env":{}}}