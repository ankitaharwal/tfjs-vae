{"dependencies":[{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\package.json","includedInParent":true,"mtime":1528200878026},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\.babelrc","includedInParent":true,"mtime":1528197961732},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1524501157000},{"name":"@tensorflow/tfjs-core","loc":{"line":13,"column":26}},{"name":"../activations","loc":{"line":14,"column":28}},{"name":"../backend/tfjs_backend","loc":{"line":15,"column":16}},{"name":"../common","loc":{"line":16,"column":23}},{"name":"../constraints","loc":{"line":17,"column":28}},{"name":"../engine/topology","loc":{"line":18,"column":25}},{"name":"../errors","loc":{"line":19,"column":23}},{"name":"../initializers","loc":{"line":20,"column":29}},{"name":"../regularizers","loc":{"line":21,"column":29}},{"name":"../types","loc":{"line":22,"column":22}},{"name":"../utils/conv_utils","loc":{"line":23,"column":27}},{"name":"../utils/generic_utils","loc":{"line":24,"column":28}}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar activations_1 = require(\"../activations\");\nvar K = require(\"../backend/tfjs_backend\");\nvar common_1 = require(\"../common\");\nvar constraints_1 = require(\"../constraints\");\nvar topology_1 = require(\"../engine/topology\");\nvar errors_1 = require(\"../errors\");\nvar initializers_1 = require(\"../initializers\");\nvar regularizers_1 = require(\"../regularizers\");\nvar types_1 = require(\"../types\");\nvar conv_utils_1 = require(\"../utils/conv_utils\");\nvar generic_utils = require(\"../utils/generic_utils\");\nvar Conv = (function (_super) {\n    __extends(Conv, _super);\n    function Conv(rank, config) {\n        var _this = _super.call(this, config) || this;\n        _this.kernel = null;\n        _this.bias = null;\n        _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        _this.rank = rank;\n        if (_this.rank !== 1 && _this.rank !== 2) {\n            throw new errors_1.NotImplementedError(\"Convolution layer for rank other than 1 or 2 (\" + _this.rank + \") is \" +\n                \"not implemented yet.\");\n        }\n        _this.filters = config.filters;\n        _this.kernelSize = conv_utils_1.normalizeArray(config.kernelSize, rank, 'kernelSize');\n        _this.strides = conv_utils_1.normalizeArray(config.strides == null ? 1 : config.strides, rank, 'strides');\n        _this.padding = config.padding == null ? 'valid' : config.padding;\n        common_1.checkPaddingMode(_this.padding);\n        _this.dataFormat =\n            config.dataFormat == null ? 'channelsLast' : config.dataFormat;\n        common_1.checkDataFormat(_this.dataFormat);\n        _this.dilationRate = config.dilationRate == null ? 1 : config.dilationRate;\n        if (_this.rank === 1 &&\n            (Array.isArray(_this.dilationRate) &&\n                _this.dilationRate.length !== 1)) {\n            throw new errors_1.ValueError(\"dilationRate must be a number or an array of a single number \" +\n                \"for 1D convolution, but received \" +\n                (\"\" + JSON.stringify(_this.dilationRate)));\n        }\n        if (_this.rank === 2) {\n            if (typeof _this.dilationRate === 'number') {\n                _this.dilationRate = [_this.dilationRate, _this.dilationRate];\n            }\n            else if (_this.dilationRate.length !== 2) {\n                throw new errors_1.ValueError(\"dilationRate must be a number or array of two numbers for 2D \" +\n                    (\"convolution, but received \" + JSON.stringify(_this.dilationRate)));\n            }\n        }\n        _this.activation = activations_1.getActivation(config.activation);\n        _this.useBias = config.useBias == null ? true : config.useBias;\n        _this.kernelInitializer = initializers_1.getInitializer(config.kernelInitializer || _this.DEFAULT_KERNEL_INITIALIZER);\n        _this.biasInitializer =\n            initializers_1.getInitializer(config.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n        _this.kernelConstraint = constraints_1.getConstraint(config.kernelConstraint);\n        _this.biasConstraint = constraints_1.getConstraint(config.biasConstraint);\n        _this.kernelRegularizer = regularizers_1.getRegularizer(config.kernelRegularizer);\n        _this.biasRegularizer = regularizers_1.getRegularizer(config.biasRegularizer);\n        _this.activityRegularizer = regularizers_1.getRegularizer(config.activityRegularizer);\n        return _this;\n    }\n    Conv.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new errors_1.ValueError(\"The channel dimension of the input should be defined. \" +\n                (\"Found \" + inputShape[channelAxis]));\n        }\n        var inputDim = inputShape[channelAxis];\n        var kernelShape = this.kernelSize.concat([inputDim, this.filters]);\n        this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        this.inputSpec = [{ ndim: this.rank + 2, axes: (_a = {}, _a[channelAxis] = inputDim, _a) }];\n        this.built = true;\n        var _a;\n    };\n    Conv.prototype.call = function (inputs, kwargs) {\n        inputs = generic_utils.getExactlyOneTensor(inputs);\n        var outputs;\n        var biasValue = this.bias == null ? null : this.bias.read();\n        if (this.rank === 1) {\n            outputs = K.conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate);\n        }\n        else if (this.rank === 2) {\n            outputs = K.conv2dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);\n        }\n        else if (this.rank === 3) {\n            throw new errors_1.NotImplementedError('3D convolution is not implemented yet.');\n        }\n        if (this.activation != null) {\n            outputs = this.activation(outputs);\n        }\n        return outputs;\n    };\n    Conv.prototype.computeOutputShape = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var newSpace = [];\n        var space = (this.dataFormat === 'channelsLast') ?\n            inputShape.slice(1, inputShape.length - 1) :\n            inputShape.slice(2);\n        for (var i = 0; i < space.length; ++i) {\n            var newDim = conv_utils_1.convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === 'number' ? this.dilationRate :\n                this.dilationRate[i]);\n            newSpace.push(newDim);\n        }\n        var outputShape = [inputShape[0]];\n        if (this.dataFormat === 'channelsLast') {\n            outputShape = outputShape.concat(newSpace);\n            outputShape.push(this.filters);\n        }\n        else {\n            outputShape.push(this.filters);\n            outputShape = outputShape.concat(newSpace);\n        }\n        return outputShape;\n    };\n    Conv.prototype.getConfig = function () {\n        var config = {\n            rank: this.rank,\n            filters: this.filters,\n            kernelSize: this.kernelSize,\n            strides: this.strides,\n            padding: this.padding,\n            dataFormat: this.dataFormat,\n            dilationRate: this.dilationRate,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint)\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return Conv;\n}(topology_1.Layer));\nexports.Conv = Conv;\nvar Conv2D = (function (_super) {\n    __extends(Conv2D, _super);\n    function Conv2D(config) {\n        return _super.call(this, 2, config) || this;\n    }\n    Conv2D.prototype.getClassName = function () {\n        return 'Conv2D';\n    };\n    Conv2D.prototype.getConfig = function () {\n        var config = _super.prototype.getConfig.call(this);\n        delete config['rank'];\n        return config;\n    };\n    return Conv2D;\n}(Conv));\nexports.Conv2D = Conv2D;\ngeneric_utils.ClassNameMap.register('Conv2D', Conv2D);\nvar Conv2DTranspose = (function (_super) {\n    __extends(Conv2DTranspose, _super);\n    function Conv2DTranspose(config) {\n        var _this = _super.call(this, config) || this;\n        _this.inputSpec = [new topology_1.InputSpec({ ndim: 4 })];\n        if (_this.padding !== 'same' && _this.padding !== 'valid') {\n            throw new errors_1.ValueError(\"Conv2DTranspose currently supports only padding modes 'same' \" +\n                (\"and 'valid', but received padding mode \" + _this.padding));\n        }\n        return _this;\n    }\n    Conv2DTranspose.prototype.getClassName = function () {\n        return 'Conv2DTranspose';\n    };\n    Conv2DTranspose.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        if (inputShape.length !== 4) {\n            throw new errors_1.ValueError('Input should have rank 4; Received input shape: ' +\n                JSON.stringify(inputShape));\n        }\n        var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new errors_1.ValueError('The channel dimension of the inputs should be defined. ' +\n                'Found `None`.');\n        }\n        var inputDim = inputShape[channelAxis];\n        var kernelShape = this.kernelSize.concat([this.filters, inputDim]);\n        this.kernel = this.addWeight('kernel', kernelShape, types_1.DType.float32, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], types_1.DType.float32, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        this.inputSpec =\n            [new topology_1.InputSpec({ ndim: 4, axes: (_a = {}, _a[channelAxis] = inputDim, _a) })];\n        this.built = true;\n        var _a;\n    };\n    Conv2DTranspose.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            var input = generic_utils.getExactlyOneTensor(inputs);\n            if (input.shape.length !== 4) {\n                throw new errors_1.ValueError(\"Conv2DTranspose.call() expects input tensor to be rank-4, but \" +\n                    (\"received a tensor of rank-\" + input.shape.length));\n            }\n            var inputShape = input.shape;\n            var batchSize = inputShape[0];\n            var hAxis;\n            var wAxis;\n            if (_this.dataFormat === 'channelsFirst') {\n                hAxis = 2;\n                wAxis = 3;\n            }\n            else {\n                hAxis = 1;\n                wAxis = 2;\n            }\n            var height = inputShape[hAxis];\n            var width = inputShape[wAxis];\n            var kernelH = _this.kernelSize[0];\n            var kernelW = _this.kernelSize[1];\n            var strideH = _this.strides[0];\n            var strideW = _this.strides[1];\n            var outHeight = conv_utils_1.deconvLength(height, strideH, kernelH, _this.padding);\n            var outWidth = conv_utils_1.deconvLength(width, strideW, kernelW, _this.padding);\n            var outputShape = [batchSize, outHeight, outWidth, _this.filters];\n            if (_this.dataFormat !== 'channelsLast') {\n                input = K.transpose(input, [0, 2, 3, 1]);\n            }\n            var outputs = tfjs_core_1.conv2dTranspose(input, _this.kernel.read(), outputShape, _this.strides, _this.padding);\n            if (_this.dataFormat !== 'channelsLast') {\n                outputs = K.transpose(outputs, [0, 3, 1, 2]);\n            }\n            if (_this.bias != null) {\n                outputs =\n                    K.biasAdd(outputs, _this.bias.read(), _this.dataFormat);\n            }\n            if (_this.activation != null) {\n                outputs = _this.activation(outputs);\n            }\n            return outputs;\n        });\n    };\n    Conv2DTranspose.prototype.computeOutputShape = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var outputShape = inputShape.slice();\n        var channelAxis;\n        var heightAxis;\n        var widthAxis;\n        if (this.dataFormat === 'channelsFirst') {\n            channelAxis = 1;\n            heightAxis = 2;\n            widthAxis = 3;\n        }\n        else {\n            channelAxis = 3;\n            heightAxis = 1;\n            widthAxis = 2;\n        }\n        var kernelH = this.kernelSize[0];\n        var kernelW = this.kernelSize[1];\n        var strideH = this.strides[0];\n        var strideW = this.strides[1];\n        outputShape[channelAxis] = this.filters;\n        outputShape[heightAxis] =\n            conv_utils_1.deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);\n        outputShape[widthAxis] =\n            conv_utils_1.deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);\n        return outputShape;\n    };\n    Conv2DTranspose.prototype.getConfig = function () {\n        var config = _super.prototype.getConfig.call(this);\n        delete config['dilationRate'];\n        return config;\n    };\n    return Conv2DTranspose;\n}(Conv2D));\nexports.Conv2DTranspose = Conv2DTranspose;\ngeneric_utils.ClassNameMap.register('Conv2DTranspose', Conv2DTranspose);\nvar SeparableConv = (function (_super) {\n    __extends(SeparableConv, _super);\n    function SeparableConv(rank, config) {\n        var _this = _super.call(this, rank, config) || this;\n        _this.DEFAULT_DEPTHWISE_INITIALIZER = 'glorotUniform';\n        _this.DEFAULT_POINTWISE_INITIALIZER = 'glorotUniform';\n        _this.depthwiseKernel = null;\n        _this.pointwiseKernel = null;\n        if (config.filters == null) {\n            throw new errors_1.ValueError('The `filters` configuration field is required by SeparableConv, ' +\n                'but is unspecified.');\n        }\n        if (config.kernelInitializer != null || config.kernelRegularizer != null ||\n            config.kernelConstraint != null) {\n            throw new errors_1.ValueError('Fields kernelInitializer, kernelRegularizer and kernelConstraint ' +\n                'are invalid for SeparableConv2D. Use depthwiseInitializer, ' +\n                'depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, ' +\n                'pointwiseRegularizer and pointwiseConstraint instead.');\n        }\n        if (config.padding != null && config.padding !== 'same' &&\n            config.padding !== 'valid') {\n            throw new errors_1.ValueError(\"SeparableConv\" + _this.rank + \"D supports only padding modes: \" +\n                (\"'same' and 'valid', but received \" + JSON.stringify(config.padding)));\n        }\n        _this.depthMultiplier =\n            config.depthMultiplier == null ? 1 : config.depthMultiplier;\n        _this.depthwiseInitializer = initializers_1.getInitializer(config.depthwiseInitializer || _this.DEFAULT_DEPTHWISE_INITIALIZER);\n        _this.depthwiseRegularizer = regularizers_1.getRegularizer(config.depthwiseRegularizer);\n        _this.depthwiseConstraint = constraints_1.getConstraint(config.depthwiseConstraint);\n        _this.pointwiseInitializer = initializers_1.getInitializer(config.depthwiseInitializer || _this.DEFAULT_POINTWISE_INITIALIZER);\n        _this.pointwiseRegularizer = regularizers_1.getRegularizer(config.pointwiseRegularizer);\n        _this.pointwiseConstraint = constraints_1.getConstraint(config.pointwiseConstraint);\n        return _this;\n    }\n    SeparableConv.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        if (inputShape.length < this.rank + 2) {\n            throw new errors_1.ValueError(\"Inputs to SeparableConv\" + this.rank + \"D should have rank \" +\n                (this.rank + 2 + \", but received input shape: \") +\n                (\"\" + JSON.stringify(inputShape)));\n        }\n        var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n            throw new errors_1.ValueError(\"The channel dimension of the inputs should be defined, \" +\n                (\"but found \" + JSON.stringify(inputShape[channelAxis])));\n        }\n        var inputDim = inputShape[channelAxis];\n        var depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);\n        var pointwiseKernelShape = [];\n        for (var i = 0; i < this.rank; ++i) {\n            pointwiseKernelShape.push(1);\n        }\n        pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);\n        var trainable = true;\n        this.depthwiseKernel = this.addWeight('depthwise_kernel', depthwiseKernelShape, types_1.DType.float32, this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);\n        this.pointwiseKernel = this.addWeight('pointwise_kernel', pointwiseKernelShape, types_1.DType.float32, this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], types_1.DType.float32, this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.inputSpec =\n            [new topology_1.InputSpec({ ndim: this.rank + 2, axes: (_a = {}, _a[channelAxis] = inputDim, _a) })];\n        this.built = true;\n        var _a;\n    };\n    SeparableConv.prototype.call = function (inputs, kwargs) {\n        inputs = generic_utils.getExactlyOneTensor(inputs);\n        var output;\n        if (this.rank === 1) {\n            throw new errors_1.NotImplementedError('1D separable convolution is not implemented yet.');\n        }\n        else if (this.rank === 2) {\n            if (this.dataFormat === 'channelsFirst') {\n                inputs = K.transpose(inputs, [0, 2, 3, 1]);\n            }\n            output = tfjs_core_1.separableConv2d(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, 'NHWC');\n        }\n        if (this.useBias) {\n            output = K.biasAdd(output, this.bias.read(), this.dataFormat);\n        }\n        if (this.activation != null) {\n            output = this.activation(output);\n        }\n        if (this.dataFormat === 'channelsFirst') {\n            output = K.transpose(output, [0, 3, 1, 2]);\n        }\n        return output;\n    };\n    SeparableConv.prototype.getClassName = function () {\n        return 'SeparableConv';\n    };\n    SeparableConv.prototype.getConfig = function () {\n        var config = _super.prototype.getConfig.call(this);\n        delete config['rank'];\n        delete config['kernelInitializer'];\n        delete config['kernelRegularizer'];\n        delete config['kernelConstraint'];\n        config['depthwiseInitializer'] =\n            initializers_1.serializeInitializer(this.depthwiseInitializer);\n        config['pointwiseInitializer'] =\n            initializers_1.serializeInitializer(this.pointwiseInitializer);\n        config['depthwiseRegularizer'] =\n            regularizers_1.serializeRegularizer(this.depthwiseRegularizer);\n        config['pointwiseRegularizer'] =\n            regularizers_1.serializeRegularizer(this.pointwiseRegularizer);\n        config['depthwiseConstraint'] =\n            constraints_1.serializeConstraint(this.depthwiseConstraint);\n        config['pointwiseConstraint'] =\n            constraints_1.serializeConstraint(this.pointwiseConstraint);\n        return config;\n    };\n    return SeparableConv;\n}(Conv));\nexports.SeparableConv = SeparableConv;\nvar SeparableConv2D = (function (_super) {\n    __extends(SeparableConv2D, _super);\n    function SeparableConv2D(config) {\n        return _super.call(this, 2, config) || this;\n    }\n    SeparableConv2D.prototype.getClassName = function () {\n        return 'SeparableConv2D';\n    };\n    return SeparableConv2D;\n}(SeparableConv));\nexports.SeparableConv2D = SeparableConv2D;\ngeneric_utils.ClassNameMap.register('SeparableConv2D', SeparableConv2D);\nvar Conv1D = (function (_super) {\n    __extends(Conv1D, _super);\n    function Conv1D(config) {\n        var _this = _super.call(this, 1, config) || this;\n        _this.inputSpec = [{ ndim: 3 }];\n        return _this;\n    }\n    Conv1D.prototype.getClassName = function () {\n        return 'Conv1D';\n    };\n    Conv1D.prototype.getConfig = function () {\n        var config = _super.prototype.getConfig.call(this);\n        delete config['rank'];\n        delete config['dataFormat'];\n        return config;\n    };\n    return Conv1D;\n}(Conv));\nexports.Conv1D = Conv1D;\ngeneric_utils.ClassNameMap.register('Conv1D', Conv1D);\n"},"hash":"87442571799fed570ec9b6c388f7ee1c","cacheData":{"env":{}}}